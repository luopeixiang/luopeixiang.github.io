---
layout:     post
title:      "潜在语义分析"
subtitle:   ""
date:       2018-11-08
author:     "MaggicQ"
header-img: "img/post-bg-e2e-ux.jpg"
tags:
    - 信息检索
    - LSA
---

**本文目录**
* TOC
{:toc}



## 潜在语义分析（Latent Semantic Analysis）

传统向量空间模型使用精确的词匹配，即精确匹配用户输入的词与向量空间中存在的词。由于一词多义(polysemy)和一义多词(synonymy)的存在，使得该模型无法提供给用户语义层面的检索。比如用户搜索”automobile”，即汽车，传统向量空间模型仅仅会返回包含”automobile”单词的页面，而实际上包含”car”单词的页面也可能是用户所需要的。

 LSA(latent semantic analysis)潜在语义分析，也被称为LSI(latent semantic index)，就是为了解决这个问题而被提出来的，它的**做法是**找出词(terms)在文档和查询中真正的含义，也就是潜在语义，从而解决上面描述的问题。具体说来就是对一个大型的文档集合使用一个合理的维度建模，并将词和文档都表示到该空间，比如有2000个文档，包含7000个索引词，LSA使用一个维度为100的向量空间将文档和词表示到该空间，进而在该空间进行信息检索。而将文档表示到此空间的过程就是SVD奇异值分解和降维的过程。**降维是LSA分析中最重要的一步**，通过降维，去除了文档中的“噪音”，也就是无关信息（比如词的误用或不相关的词偶尔出现在一起），语义结构逐渐呈现。**相比传统向量空间**，潜在语义空间的维度更小，语义关系更明确。

LSA的步骤如下 :

* 分析文档集合，建立Term-Document矩阵。
*  对Term-Document矩阵进行奇异值分解。
* 对SVD分解后的矩阵进行降维，也就是[奇异值分解](/2018/09/18/奇异值分解/)所提到的低阶近似。
*  使用降维后的矩阵构建潜在语义空间，或重建Term-Document矩阵。



## 参考
[主题模型TopicModel：LSA（隐性语义分析）模型和其实现的早期方法SVD](https://blog.csdn.net/pipisorry/article/details/42560331)